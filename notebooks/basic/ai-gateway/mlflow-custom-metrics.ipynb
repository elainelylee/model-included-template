{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae163843-4197-4c3e-b5d5-8a65d2c5aa62",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from mlflow.deployments import get_deploy_client\n",
    "import os\n",
    "os.environ['MLFLOW_DEPLOYMENTS_TARGET']='http://127.0.0.1:8767'\n",
    "#DOMINO_MLFLOW_DEPLOYMENTS\n",
    "client = get_deploy_client(os.environ['MLFLOW_DEPLOYMENTS_TARGET'])\n",
    "\n",
    "response = client.predict(\n",
    "\tendpoint=\"sw-completions\", \n",
    "\tinputs={\"prompt\": \"It's one small step for\",\n",
    "            #\"n\":2, \n",
    "            #\"temperature\":0.5, \n",
    "            #\"max_tokens\":50, \n",
    "            #\"stop\":[]\n",
    "           }\n",
    ")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "870707c6-bdce-49da-b26c-9f3662686410",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlflow.deployments import get_deploy_client\n",
    "import os\n",
    "\n",
    "client = get_deploy_client(os.environ['DOMINO_MLFLOW_DEPLOYMENTS'])\n",
    "\n",
    "response = client.predict(\n",
    "\tendpoint=\"sw-completions\",\n",
    "\t#inputs={\"messages\": [{\"role\": \"user\", \"content\": \"Tell me a joke about rabbits\"}]}\n",
    "    inputs={\"prompt\": \"Tell me a joke about rabbits\"}\n",
    ")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20bb1f58-5709-455a-9b90-197124857b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "professionalism_example_score_2 = mlflow.metrics.genai.EvaluationExample(\n",
    "    input=\"What is MLflow?\",\n",
    "    output=(\n",
    "        \"MLflow is like your friendly neighborhood toolkit for managing your machine learning projects. It helps \"\n",
    "        \"you track experiments, package your code and models, and collaborate with your team, making the whole ML \"\n",
    "        \"workflow smoother. It's like your Swiss Army knife for machine learning!\"\n",
    "    ),\n",
    "    score=2,\n",
    "    justification=(\n",
    "        \"The response is written in a casual tone. It uses contractions, filler words such as 'like', and \"\n",
    "        \"exclamation points, which make it sound less professional. \"\n",
    "    ),\n",
    ")\n",
    "professionalism_example_score_4 = mlflow.metrics.genai.EvaluationExample(\n",
    "    input=\"What is MLflow?\",\n",
    "    output=(\n",
    "        \"MLflow is an open-source platform for managing the end-to-end machine learning (ML) lifecycle. It was \"\n",
    "        \"developed by Databricks, a company that specializes in big data and machine learning solutions. MLflow is \"\n",
    "        \"designed to address the challenges that data scientists and machine learning engineers face when \"\n",
    "        \"developing, training, and deploying machine learning models.\",\n",
    "    ),\n",
    "    score=4,\n",
    "    justification=(\"The response is written in a formal language and a neutral tone. \"),\n",
    ")\n",
    "professionalism_example_score_2 = mlflow.metrics.genai.EvaluationExample(\n",
    "    input=\"What is MLflow?\",\n",
    "    output=(\n",
    "        \"MLflow is like your friendly neighborhood toolkit for managing your machine learning projects. It helps \"\n",
    "        \"you track experiments, package your code and models, and collaborate with your team, making the whole ML \"\n",
    "        \"workflow smoother. It's like your Swiss Army knife for machine learning!\"\n",
    "    ),\n",
    "    score=2,\n",
    "    justification=(\n",
    "        \"The response is written in a casual tone. It uses contractions, filler words such as 'like', and \"\n",
    "        \"exclamation points, which make it sound less professional. \"\n",
    "    ),\n",
    ")\n",
    "professionalism_example_score_4 = mlflow.metrics.genai.EvaluationExample(\n",
    "    input=\"What is MLflow?\",\n",
    "    output=(\n",
    "        \"MLflow is an open-source platform for managing the end-to-end machine learning (ML) lifecycle. It was \"\n",
    "        \"developed by Databricks, a company that specializes in big data and machine learning solutions. MLflow is \"\n",
    "        \"designed to address the challenges that data scientists and machine learning engineers face when \"\n",
    "        \"developing, training, and deploying machine learning models.\",\n",
    "    ),\n",
    "    score=4,\n",
    "    justification=(\"The response is written in a formal language and a neutral tone. \"),\n",
    ")\n",
    "professionalism = mlflow.metrics.genai.make_genai_metric(\n",
    "    name=\"professionalism\",\n",
    "    definition=(\n",
    "        \"Professionalism refers to the use of a formal, respectful, and appropriate style of communication that is \"\n",
    "        \"tailored to the context and audience. It often involves avoiding overly casual language, slang, or \"\n",
    "        \"colloquialisms, and instead using clear, concise, and respectful language.\"\n",
    "    ),\n",
    "    grading_prompt=(\n",
    "        \"Professionalism: If the answer is written using a professional tone, below are the details for different scores: \"\n",
    "        \"- Score 0: Language is extremely casual, informal, and may include slang or colloquialisms. Not suitable for \"\n",
    "        \"professional contexts.\"\n",
    "        \"- Score 1: Language is casual but generally respectful and avoids strong informality or slang. Acceptable in \"\n",
    "        \"some informal professional settings.\"\n",
    "        \"- Score 2: Language is overall formal but still have casual words/phrases. Borderline for professional contexts.\"\n",
    "        \"- Score 3: Language is balanced and avoids extreme informality or formality. Suitable for most professional contexts. \"\n",
    "        \"- Score 4: Language is noticeably formal, respectful, and avoids casual elements. Appropriate for formal \"\n",
    "        \"business or academic settings. \"\n",
    "    ),\n",
    "    examples=[professionalism_example_score_2, professionalism_example_score_4],\n",
    "    #model=\"openai:/gpt-3.5-turbo-16k\", #This one gives the correct response \n",
    "    #model = \"endpoints:/http://127.0.0.1:8767/gateway/sw-completions/invocations\", #This one fails and so does the next one\n",
    "    model = \"endpoints:/sw-completions\",\n",
    "    parameters={\"temperature\": 0.0},\n",
    "    aggregations=[\"mean\", \"variance\"],\n",
    "    greater_is_better=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd1b11d-ae7a-43f5-96ea-4cfdecd780b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['MLFLOW_DEPLOYMENTS_TARGET']=os.environ['DOMINO_MLFLOW_DEPLOYMENTS']\n",
    "import mlflow\n",
    "import openai\n",
    "import os\n",
    "import pandas as pd\n",
    "from getpass import getpass\n",
    "os.environ['OPENAI_API_KEY']=''\n",
    "#os.environ['MLFLOW_TRACKING_URI'] = 'http://127.0.0.1:8080/'\n",
    "eval_data = pd.DataFrame(\n",
    "    {\n",
    "        \"inputs\": [\n",
    "            \"What is MLflow?\",\n",
    "            \"What is Spark?\",\n",
    "        ],\n",
    "        \"ground_truth\": [\n",
    "            \"MLflow is an open-source platform for managing the end-to-end machine learning (ML) \"\n",
    "            \"lifecycle. It was developed by Databricks, a company that specializes in big data and \"\n",
    "            \"machine learning solutions. MLflow is designed to address the challenges that data \"\n",
    "            \"scientists and machine learning engineers face when developing, training, and deploying \"\n",
    "            \"machine learning models.\",\n",
    "            \"Apache Spark is an open-source, distributed computing system designed for big data \"\n",
    "            \"processing and analytics. It was developed in response to limitations of the Hadoop \"\n",
    "            \"MapReduce computing model, offering improvements in speed and ease of use. Spark \"\n",
    "            \"provides libraries for various tasks such as data ingestion, processing, and analysis \"\n",
    "            \"through its components like Spark SQL for structured data, Spark Streaming for \"\n",
    "            \"real-time data processing, and MLlib for machine learning tasks\",\n",
    "        ],\n",
    "    }\n",
    ")\n",
    "experiment = mlflow.set_experiment(\"Test LLM Experiment\")\n",
    "with mlflow.start_run() as run:\n",
    "    system_prompt = \"Answer the following question in two sentences\"\n",
    "    # Wrap \"gpt-4\" as an MLflow model.\n",
    "    logged_model_info = mlflow.openai.log_model(\n",
    "        model=\"gpt-4\",\n",
    "        task=openai.chat.completions,\n",
    "        artifact_path=\"model\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": \"{question}\"},\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    # Use predefined question-answering metrics to evaluate our model.\n",
    "    results = mlflow.evaluate(\n",
    "        logged_model_info.model_uri,\n",
    "        eval_data,\n",
    "        targets=\"ground_truth\",\n",
    "        model_type=\"question-answering\",\n",
    "        extra_metrics=[mlflow.metrics.toxicity(), mlflow.metrics.latency(),professionalism],\n",
    "    )\n",
    "    print(f\"See aggregated evaluation results below: \\n{results.metrics}\")\n",
    "\n",
    "    # Evaluation result for each data record is available in `results.tables`.\n",
    "    eval_table = results.tables[\"eval_results_table\"]\n",
    "    print(f\"See evaluation table below: \\n{eval_table}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efbcd19e-aaa4-40fe-9d33-4f154fd37662",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import os\n",
    "logged_model = 'runs:/e99714e9db384823ac07b76172746955/model'\n",
    "\n",
    "# Load model as a PyFuncModel.\n",
    "loaded_model = mlflow.pyfunc.load_model(logged_model)\n",
    "\n",
    "# Predict on a Pandas DataFrame.\n",
    "import pandas as pd\n",
    "\n",
    "out = loaded_model.predict(pd.DataFrame({\"input\": [\"What is MLflow?\",\"What is Hadoop?\"]}))\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e5955a-fa55-45f1-b7d1-11ca47ab75a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import mlflow\n",
    "\n",
    "\n",
    "def predict(data):\n",
    "    from mlflow.gateway import MlflowGatewayClient\n",
    "\n",
    "    client = MlflowGatewayClient(os.environ[\"MLFLOW_GATEWAY_URI\"])\n",
    "\n",
    "    payload = data.to_dict(orient=\"records\")\n",
    "    return [\n",
    "        client.query(route=\"completions-claude\", data=query)[\"choices\"][0][\"text\"]\n",
    "        for query in payload\n",
    "    ]\n",
    "\n",
    "\n",
    "input_example = pd.DataFrame.from_dict(\n",
    "    {\"prompt\": [\"Where is the moon?\", \"What is a comet made of?\"]}\n",
    ")\n",
    "signature = mlflow.models.infer_signature(\n",
    "    input_example, [\"Above our heads.\", \"It's mostly ice and rocks.\"]\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e30f31f4-cae5-4ef8-ae0d-38704c6537e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with mlflow.start_run():\n",
    "    model_info = mlflow.pyfunc.log_model(\n",
    "        python_model=predict,\n",
    "        registered_model_name=\"anthropic_completions\",\n",
    "        artifact_path=\"anthropic_completions\",\n",
    "        input_example=input_example,\n",
    "        signature=signature,\n",
    "    )\n",
    "\n",
    "df = pd.DataFrame.from_dict(\n",
    "    {\n",
    "        \"prompt\": [\"Tell me about Jupiter\", \"Tell me about Saturn\"],\n",
    "        \"temperature\": 0.6,\n",
    "        \"max_records\": 500,\n",
    "    }\n",
    ")\n",
    "\n",
    "loaded_model = mlflow.pyfunc.load_model(model_info.model_uri)\n",
    "\n",
    "print(loaded_model.predict(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "158157a5-e36b-458a-96c2-fb44ef10ffb7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7babbc0a-a744-4600-b657-a18c15685d93",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f86e21f-979b-45a2-b2af-da70a080403e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bd67831-fa12-44b0-baba-ceea949264f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a7305f-88fc-47e7-b0c5-35ac9926c70b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "dca-init": "true",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
