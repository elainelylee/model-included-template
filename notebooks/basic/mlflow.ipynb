{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "785bf18e-17c4-40ae-b31d-738a46925d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "!sudo /opt/conda/bin/pip install mlflow==2.13.0\n",
    "!sudo /opt/conda/bin/pip install pydantic\n",
    "!sudo /opt/conda/bin/pip install starlette\n",
    "!sudo /opt/conda/bin/pip install openai\n",
    "!sudo /opt/conda/bin/pip install tiktoken\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae163843-4197-4c3e-b5d5-8a65d2c5aa62",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlflow.deployments import get_deploy_client\n",
    "import os\n",
    "\n",
    "client = get_deploy_client(os.environ['DOMINO_MLFLOW_DEPLOYMENTS'])\n",
    "\n",
    "response = client.predict(\n",
    "\tendpoint=\"sw-completions\", \n",
    "\tinputs={\"prompt\": \"It's one small step for\",\n",
    "            #\"n\":2, \n",
    "            #\"temperature\":0.5, \n",
    "            #\"max_tokens\":50, \n",
    "            #\"stop\":[]\n",
    "           }\n",
    ")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "870707c6-bdce-49da-b26c-9f3662686410",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlflow.deployments import get_deploy_client\n",
    "import os\n",
    "\n",
    "client = get_deploy_client(os.environ['DOMINO_MLFLOW_DEPLOYMENTS'])\n",
    "\n",
    "response = client.predict(\n",
    "\tendpoint=\"sw-completions\",\n",
    "\t#inputs={\"messages\": [{\"role\": \"user\", \"content\": \"Tell me a joke about rabbits\"}]}\n",
    "    inputs={\"prompt\": \"Tell me a joke about rabbits\"}\n",
    ")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20bb1f58-5709-455a-9b90-197124857b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "professionalism_example_score_2 = mlflow.metrics.genai.EvaluationExample(\n",
    "    input=\"What is MLflow?\",\n",
    "    output=(\n",
    "        \"MLflow is like your friendly neighborhood toolkit for managing your machine learning projects. It helps \"\n",
    "        \"you track experiments, package your code and models, and collaborate with your team, making the whole ML \"\n",
    "        \"workflow smoother. It's like your Swiss Army knife for machine learning!\"\n",
    "    ),\n",
    "    score=2,\n",
    "    justification=(\n",
    "        \"The response is written in a casual tone. It uses contractions, filler words such as 'like', and \"\n",
    "        \"exclamation points, which make it sound less professional. \"\n",
    "    ),\n",
    ")\n",
    "professionalism_example_score_4 = mlflow.metrics.genai.EvaluationExample(\n",
    "    input=\"What is MLflow?\",\n",
    "    output=(\n",
    "        \"MLflow is an open-source platform for managing the end-to-end machine learning (ML) lifecycle. It was \"\n",
    "        \"developed by Databricks, a company that specializes in big data and machine learning solutions. MLflow is \"\n",
    "        \"designed to address the challenges that data scientists and machine learning engineers face when \"\n",
    "        \"developing, training, and deploying machine learning models.\",\n",
    "    ),\n",
    "    score=4,\n",
    "    justification=(\"The response is written in a formal language and a neutral tone. \"),\n",
    ")\n",
    "professionalism_example_score_2 = mlflow.metrics.genai.EvaluationExample(\n",
    "    input=\"What is MLflow?\",\n",
    "    output=(\n",
    "        \"MLflow is like your friendly neighborhood toolkit for managing your machine learning projects. It helps \"\n",
    "        \"you track experiments, package your code and models, and collaborate with your team, making the whole ML \"\n",
    "        \"workflow smoother. It's like your Swiss Army knife for machine learning!\"\n",
    "    ),\n",
    "    score=2,\n",
    "    justification=(\n",
    "        \"The response is written in a casual tone. It uses contractions, filler words such as 'like', and \"\n",
    "        \"exclamation points, which make it sound less professional. \"\n",
    "    ),\n",
    ")\n",
    "professionalism_example_score_4 = mlflow.metrics.genai.EvaluationExample(\n",
    "    input=\"What is MLflow?\",\n",
    "    output=(\n",
    "        \"MLflow is an open-source platform for managing the end-to-end machine learning (ML) lifecycle. It was \"\n",
    "        \"developed by Databricks, a company that specializes in big data and machine learning solutions. MLflow is \"\n",
    "        \"designed to address the challenges that data scientists and machine learning engineers face when \"\n",
    "        \"developing, training, and deploying machine learning models.\",\n",
    "    ),\n",
    "    score=4,\n",
    "    justification=(\"The response is written in a formal language and a neutral tone. \"),\n",
    ")\n",
    "professionalism = mlflow.metrics.genai.make_genai_metric(\n",
    "    name=\"professionalism\",\n",
    "    definition=(\n",
    "        \"Professionalism refers to the use of a formal, respectful, and appropriate style of communication that is \"\n",
    "        \"tailored to the context and audience. It often involves avoiding overly casual language, slang, or \"\n",
    "        \"colloquialisms, and instead using clear, concise, and respectful language.\"\n",
    "    ),\n",
    "    grading_prompt=(\n",
    "        \"Professionalism: If the answer is written using a professional tone, below are the details for different scores: \"\n",
    "        \"- Score 0: Language is extremely casual, informal, and may include slang or colloquialisms. Not suitable for \"\n",
    "        \"professional contexts.\"\n",
    "        \"- Score 1: Language is casual but generally respectful and avoids strong informality or slang. Acceptable in \"\n",
    "        \"some informal professional settings.\"\n",
    "        \"- Score 2: Language is overall formal but still have casual words/phrases. Borderline for professional contexts.\"\n",
    "        \"- Score 3: Language is balanced and avoids extreme informality or formality. Suitable for most professional contexts. \"\n",
    "        \"- Score 4: Language is noticeably formal, respectful, and avoids casual elements. Appropriate for formal \"\n",
    "        \"business or academic settings. \"\n",
    "    ),\n",
    "    examples=[professionalism_example_score_2, professionalism_example_score_4],\n",
    "    #model=\"openai:/gpt-3.5-turbo-16k\", #This one gives the correct response \n",
    "    #model = \"endpoints:/http://127.0.0.1:8767/gateway/sw-completions/invocations\", #This one fails and so does the next one\n",
    "    model = \"endpoints:/sw-completions\",\n",
    "    parameters={\"temperature\": 0.0},\n",
    "    aggregations=[\"mean\", \"variance\"],\n",
    "    greater_is_better=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd1b11d-ae7a-43f5-96ea-4cfdecd780b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.environ['OPENAI_API_KEY']=''\n",
    "os.environ['MLFLOW_DEPLOYMENTS_TARGET']=os.environ['DOMINO_MLFLOW_DEPLOYMENTS']\n",
    "import mlflow\n",
    "import openai\n",
    "import os\n",
    "import pandas as pd\n",
    "from getpass import getpass\n",
    "\n",
    "#os.environ['MLFLOW_TRACKING_URI'] = 'http://127.0.0.1:8080/'\n",
    "eval_data = pd.DataFrame(\n",
    "    {\n",
    "        \"inputs\": [\n",
    "            \"What is MLflow?\",\n",
    "            \"What is Spark?\",\n",
    "        ],\n",
    "        \"ground_truth\": [\n",
    "            \"MLflow is an open-source platform for managing the end-to-end machine learning (ML) \"\n",
    "            \"lifecycle. It was developed by Databricks, a company that specializes in big data and \"\n",
    "            \"machine learning solutions. MLflow is designed to address the challenges that data \"\n",
    "            \"scientists and machine learning engineers face when developing, training, and deploying \"\n",
    "            \"machine learning models.\",\n",
    "            \"Apache Spark is an open-source, distributed computing system designed for big data \"\n",
    "            \"processing and analytics. It was developed in response to limitations of the Hadoop \"\n",
    "            \"MapReduce computing model, offering improvements in speed and ease of use. Spark \"\n",
    "            \"provides libraries for various tasks such as data ingestion, processing, and analysis \"\n",
    "            \"through its components like Spark SQL for structured data, Spark Streaming for \"\n",
    "            \"real-time data processing, and MLlib for machine learning tasks\",\n",
    "        ],\n",
    "    }\n",
    ")\n",
    "experiment = mlflow.set_experiment(\"Demo-Custom-LLM-Metrics\")\n",
    "with mlflow.start_run() as run:\n",
    "    system_prompt = \"Answer the following question in two sentences\"\n",
    "    # Wrap \"gpt-4\" as an MLflow model.\n",
    "    logged_model_info = mlflow.openai.log_model(\n",
    "        model=\"gpt-4\",\n",
    "        task=openai.chat.completions,\n",
    "        artifact_path=\"model\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": \"{question}\"},\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    # Use predefined question-answering metrics to evaluate our model.\n",
    "    results = mlflow.evaluate(\n",
    "        logged_model_info.model_uri,\n",
    "        eval_data,\n",
    "        targets=\"ground_truth\",\n",
    "        model_type=\"question-answering\",\n",
    "        extra_metrics=[mlflow.metrics.toxicity(), mlflow.metrics.latency(),professionalism],\n",
    "    )\n",
    "    print(f\"See aggregated evaluation results below: \\n{results.metrics}\")\n",
    "\n",
    "    # Evaluation result for each data record is available in `results.tables`.\n",
    "    eval_table = results.tables[\"eval_results_table\"]\n",
    "    print(f\"See evaluation table below: \\n{eval_table}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efbcd19e-aaa4-40fe-9d33-4f154fd37662",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import os\n",
    "logged_model = 'runs:/06c8c99723614dc6969f6f44003d7d24/model'\n",
    "\n",
    "# Load model as a PyFuncModel.\n",
    "loaded_model = mlflow.pyfunc.load_model(logged_model)\n",
    "\n",
    "# Predict on a Pandas DataFrame.\n",
    "import pandas as pd\n",
    "\n",
    "out = loaded_model.predict(pd.DataFrame({\"input\": [\"What is MLflow?\",\"What is Hadoop?\"]}))\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e5955a-fa55-45f1-b7d1-11ca47ab75a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import mlflow\n",
    "from mlflow.deployments import get_deploy_client\n",
    "import os\n",
    "\n",
    "\n",
    "\n",
    "def predict(data):\n",
    "    \n",
    "\n",
    "    client = get_deploy_client(os.environ['DOMINO_MLFLOW_DEPLOYMENTS'])\n",
    "    payload = data.to_dict()\n",
    "    response = client.predict(\n",
    "            endpoint=\"sw-completions\", \n",
    "            inputs={\"prompt\":payload[\"prompt\"][0]}\n",
    "        )\n",
    "    return response\n",
    "        \n",
    "\n",
    "\n",
    "input_example = pd.DataFrame.from_dict(\n",
    "    {\"prompt\": [\"Where is the moon?\"]}\n",
    ")\n",
    "signature = mlflow.models.infer_signature(\n",
    "    input_example, [\"Above our heads.\"]\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e30f31f4-cae5-4ef8-ae0d-38704c6537e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with mlflow.start_run():\n",
    "    model_info = mlflow.pyfunc.log_model(\n",
    "        python_model=predict,\n",
    "        registered_model_name=\"sw-completions\",\n",
    "        artifact_path=\"sw-completions\",\n",
    "        input_example=input_example,\n",
    "        signature=signature,\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1182db12-8d7a-4e1e-b11d-96da1b842e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_dict(\n",
    "    {\n",
    "        \"prompt\": [\"Tell me about Jupiter\", \"Tell me about Saturn\"]\n",
    "    }\n",
    ")\n",
    "\n",
    "loaded_model = mlflow.pyfunc.load_model(model_info.model_uri)\n",
    "\n",
    "print(loaded_model.predict(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c40a9ee6-b7a6-443f-9a67-9b74283ac7a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlflow.deployments import get_deploy_client\n",
    "import os\n",
    "\n",
    "client = get_deploy_client(os.environ['DOMINO_MLFLOW_DEPLOYMENTS'])\n",
    "\n",
    "response = client.predict(\n",
    "\tendpoint=\"obl-compta\", \n",
    "\tinputs={\"prompt\": \"It's one small step for\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b43de0c-ec80-4f80-8005-a27617444440",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "158157a5-e36b-458a-96c2-fb44ef10ffb7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a84c0e04-b933-43b4-88f3-4908787b4acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "body_json = {\n",
    "    \"endpointName\":\"sw-completions\",\n",
    "    \"endpointType\":\"llm/v1/completions\",\n",
    "    \"endpointPermissions\":{\"isEveryoneAllowed\":False,\"userIds\":[\"6283a3966d4fd0362f8ba2a8\"]},\n",
    "    \"modelProvider\":\"openai\",\n",
    "    \"modelName\":\"gpt-4\",\n",
    "    \"modelConfig\":{\"openai_api_key\":\"\"}\n",
    "}\n",
    "my_headers = {\"Content-Type\":\"application/json\",\"X-Domino-Api-Key\":os.environ['DOMINO_USER_API_KEY']}\n",
    "\n",
    "r = requests.post(url=\"https://prod-field.cs.domino.tech/api/aigateway/v1/endpoints\",headers=my_headers,json=body_json)\n",
    "##The above succeeds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24769866-de7a-4135-bb30-5335dbf5f78f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import requests\n",
    "import os\n",
    "body_json = {   \n",
    "    \"modelName\":\"gpt-4\",\n",
    "    \"modelConfig\":{\"openai_api_key\":\"\"}\n",
    "}\n",
    "my_headers = {\"Content-Type\":\"application/json\",\"X-Domino-Api-Key\":os.environ['DOMINO_USER_API_KEY']}\n",
    "\n",
    "r = requests.patch(url=\"https://prod-field.cs.domino.tech/api/aigateway/v1/endpoints/sw-completions\",headers=my_headers,json=body_json)\n",
    "print(r.text)\n",
    "r.status_code\n",
    "## This fails with status code 400\n",
    "##{\"requestId\":\"93ad6841-9ce1-44ed-b509-88050494f857\",\"errors\":[\"domino.aigateway.implementation.domain.exceptions.GatewayEndpointAlreadyExistsException: AI Gateway endpoint with name sw-completions already exists.\"]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7babbc0a-a744-4600-b657-a18c15685d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlflow.deployments import get_deploy_client\n",
    "import os\n",
    "\n",
    "client = get_deploy_client(os.environ['DOMINO_MLFLOW_DEPLOYMENTS'])\n",
    "\n",
    "response = client.predict(\n",
    "\tendpoint=\"sw-completions\", \n",
    "\tinputs={\"prompt\": \"What is mlflow?\"}\n",
    ")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f86e21f-979b-45a2-b2af-da70a080403e",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.get_endpoint(endpoint=\"sw-completions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bd67831-fa12-44b0-baba-ceea949264f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a7305f-88fc-47e7-b0c5-35ac9926c70b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
